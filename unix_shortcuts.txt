
## below commands can be added to .bashrc or .bash_profile in your unix home directory

# increase history size. this determines how many commands are stored in history before it rolls over.
HISTFILESIZE=5000

# define alias command to reference commonly used commands
alias mysrc='cd /dev/org/app/trunk/src/'

## below commands can be used to type a new command or edit a previously executed command

# up-down arrow - move between previously types commands
# Ctrl-A - beginning of command
# Ctrl-E - end of command
# Ctrl-Left Arrow - previous argument in command line
# Ctrl-Right Arrow - next argument in command line
# Ctrl-U - clear the command
# Ctrl-K - clear the command after the cursor
# Ctrl-W - deletes the word before the cursor
# Ctrl-R - search the previously executed commands
# Tab - Autocomplete directory/files
test

# switch to last working director
cd -

# run the last executed command
!!

# run the last ls command
!ls

# do not run, only print the last ls command
!ls:p

# use arguments from last command
ls -l abc.txt
cat !$

# feed a command to for loop that outputs in multiple line using space as delimiter
for i in $(stat -s filename.txt); do echo $i; done;

## do above in only current directory
for f in *filenamepattern*; do grep -n "searchtext" "$f"; done;

#######################################################################################################
imporant find commands
#######################################################################################################
# when argument list is too large us xargs
find . -name "*.tar.gz" -print0 | xargs -0 ls -l

# find files of given pattern containing a given text in current dir and its sub directories
### grep -n prints line number
find . -type f -name "*filenamepattern*" | xargs grep -n "searchtext" 

# find all files greater than 100 MB not modified in last 60 days and delete them
find ./path_to_search/ -type f -size +100M -mtime -60 -exec ls -l {} \;

# find all files in path of given pattern and replace a given text
find ./path_to_search/ -type f -name "*sh" -exec sed -i "s/oldservername/newservername/g" {} \;
## On Solaris or certain installation sed -i option is not available, then may use perl
find ./path_to_search/ -type f -name "*sh" -exec perl -p -i -e "s/oldservername/newservername/g" {} \;

find . -type f -maxdepth 1 -name "*filenamepattern*" | xargs grep -n "searchtext" 


# On Solaris, grep -H does not print file name containing the text
# use below instead grep -l prints file name 
find . -type f -name "*filenamepattern*" -exec grep -l "searchtext" {} \;

## copy files in current dir(and sub dir) that are less than 1 day old 
### to another dir
find . -type f -mtime -1 | xargs -i cp -p {} bak_dir/
find . -type f -mtime -1 -exec cp -p {} bak_dir/  \;


## find files larger than a given size
find . -type f -size +100M -exec ls -lh {} \;

## find files larger than a given size ordered by size
find . -type f -size +100M | xargs du -h | sort -rn
find . -type f -size +100M | xargs du -skh | sort -rn

## find and remove file using inode number
### e.g. esp useful when file name has special chars
find . -inum <inode_number> -exec ls -l {} \;
## to find the inode number , use ls -li 
## to remove file, replace ls -l with rm but BE CAREFUL before deleting anything. Ensure you are deleting the file you want to delete.

-- find duplicate files by size
-- step 1 : data gathering : for the given directory (incl sub dirs), find all files of type jpg larger than 2MB and write to file
find . -type f -name "*.jpg" -size +2M -exec ls -l {} \; > ~/Desktop/large_file.txt

-- step 2 : sort the data from 1 by 5th column (numerical sort) where 5th column is size, then use awk to print records with duplicate size
cat large_file.txt | sort -t" " -k 5,5n | awk -F" " '$5 in seen{print seen[$5]; print} {seen[$5]=$0}' > large_file_duplicates.txt

-- step 3: sum up the 5th "size" column in bytes, then calculate the potential size that can be freed in GB as 
-- sum (in bytes) / (2 * 1024^3)
-- /2 is based on assumption that there are 2 duplicates and one of them needs to be retained.
awk 'NR > 5 { sum += $5 } END { print sum; }' large_file_duplicates.txt

#######################################################################################################
mail commands
#######################################################################################################

# mail a file as attachment
mpack -s "<subject>" <attachment_filepath> ToEmail@email.com

# mail one file as attachment and use another file as email body
mpack -s "<subject>" -d <body_filepath> <attachment_filepath> ToEmail@email.com

# mail file content as body
cat <body_filepath> | mailx -s "<subject>" ToEmail@email.com

# mail file content as body to multiple people
cat <body_filepath> | mailx -s "<subject>" ToEmail@email.com,ToEmail2@email.com


#######################################################################################################
IO redirection
#######################################################################################################

# suppress standard output
cat sample.txt > /dev/null

# suppress error output
cat sample.txt 2> /dev/null

# suppress standard output and then redirect error output to standard output
cat sample.txt > /dev/null 2>&1

# Option 1: from cron or command line
/user/home/scripts/test_script.sh > /user/home/log/script_log.log 2>&1

# Option 2: from within the script
/user/home/scripts/test_script.sh
exec 1>/user/home/log/script_log.log
exec 2>&1

## Reference: 
1)http://unix.stackexchange.com/questions/20469/difference-between-21-output-log-and-21-tee-output-log/20471
2)http://stackoverflow.com/questions/818255/in-the-shell-what-does-21-mean

#######################################################################################################
for loop examples
#######################################################################################################

## print all file names of a given pattern in current dir
ls -l <filenamepattern*>
for f in <filenamepattern*>; do echo $f; done;

#######################################################################################################
crontab commands
#######################################################################################################

## find all cron jobs that start after 4pm and are inactive
crontab -l | awk '{if( $1 ~ /#/) && ( $2 == '16' ) ) { print $0; }'

## find all cron jobs that start after 4pm and are active
crontab -l | awk '{if( $1 !~ /#/) && ( $2 == '16' ) ) { print $0; }'


#######################################################################################################
awk commands
#######################################################################################################

## split a file delimiter, extract 3rd column, delete leading spaces, 
###sort, get unique entries and count of unique entries
awk -F"|" '{print $3;}' file.txt | sed 's/[\t]*/d;/^[ ]*/d' | sort -u | wc -l

## split by delimiter and print the line if a condition is met e.g. 4th col = 0
awk -F"," '($4 == 0) {print $0'}' file.txt

## check if a field matches pattern and then print length of field
### e.g. check oracle object name 
awk -F"," '($4 ~ /searchtext/) {print length($4),$4;}' file.txt

## extract select columns e.g. 12,23,25 based on condition  e.g. 4th col > 0
### and then print specified header line and then column data for those select columns
awk -F"|" 'BEGIN {print "COLHDR_1|COLHDR_2|COLHDR_3"} ($4 >0) {print $12,$23,$25;}' file.txt

## extract select columns e.g. 12,23,25 
awk -F"|" '{print $12,$23,$25;}' file.txt
cut -d"|" -f12,23,25 file.txt


## extract columns based on multiple conditions
awk -F"|" '(($4 > 0 || $17 < 0) && ($21 > 200)) {print $12,$23,$25;}' file.txt

## find length of line
awk '{print NR,length($0);}' file.txt

## get first 5 characters of text from line
cut -b1-5 file.txt
awk '{print substr($0, 1,5);}' file.txt

## print specified lines and perform sed to replace
awk '{if (NR==12 || NR==72) print $0;}' file.txt | sed 's/@@/%%/g'

## determine column number for a each field data in a pipe-delimited file
awk -F"|" '(NR == 1) {for(i=1;i<=NF;i++) print i":"$i}' file.txt

## find unique values for a column in a comma-delimited file
awk -F"," '{print $2;}' file.csv | sort -u

#######################################################################################################
date commands
#######################################################################################################


## get date for previous month
### say today is 10-Dec-16
date +%Y%m -d 'last month'
201611
date +%Y%m -d 'now'
201612
date +%Y%m -d 'next month'
201701


## get year for previous month
date +%Y -d 'last month'
2016

## given a date , extract seconds
a=`date`; date +%S -d $a


## Given a file path , extract file name and dir name
full_path=/user/home/log/script_log.log
file=$(basename $full_path)
dir=$(dirname $full_path)

## To delete text to left or right of cursor in VI
x -> delete text to left of cursor
X -> delete text to right of cursor

#######################################################################################################
sed commands
#######################################################################################################

## search and replace text in a file in-place
sed -i 's/searchtext/g' file.txt

## search and replace a text with multiple-line text in-place for a file
sed -f replace_with_multiline_text.sed -i file.txt
where -f option allows to specify a sed script file
and replace_with_multiline_text.sed has below text
s/original_line/replaced_line1\
replaced_line2\
replaced_line3/

## find all matching files with text and use sed to replace with multi-line text
for f in *.txt; do echo $f; sed -f replace_with_multiline_text.sed -i $f;done
OR
find -maxdepth 1 -type f -name "{fileprefix}*" -exec sed -f replace_with_multiline_text.sed -i {} \;

## find and replace multiple texts with their replacements text in-place in one-go
find . -type f -name "{fileprefix}*" -exec "s|/root/path1|/root|newpath1|g; s|/root/path2|/root|newpath2|g;" {} \;

## BACKUP
## find files matching a given criteria and copy to specified dir
find . -type f -name "{prefix}*" -exec grep -l -i "{searchText}" {} \; -exec -cp {} backup_dir/ {} \;

-- also preserve the same directory strucutre as in original directory structure
find . -type f -name "{prefix}*" -exec grep -l -i "{searchText}" {} \; -exec -cp --parents {} backup_dir/ {} \;

#######################################################################################################
scp/sftp commands
#######################################################################################################

-- copy from remote machine to local machine
scp user@server:<remote_dir_path>/<remote_file_name> .

-- copy from local machine to remote machine
scp <local_file_path> user@server:<remote_dir_path>/<remote_file_name>

## to specify private key file explicitly
sftp -oIdentityFile=~/.ssh/customFile $user@$host


#######################################################################################################
sort commands
#######################################################################################################

## print duplicate lines
sort file.txt | uniq -cd

## count of duplicate lines
sort file.txt | uniq -cd | wc -l

#######################################################################################################
tar commands
#######################################################################################################



## create a tar file that comprises of file1 and file2
tar cvf <tar_file_name.tar> file1 file2

## create a compresses tar archive
tar cvzf <tar_file_name.tar.gz> file1 file2

## list contents of tar file
tar tvf <tar_file_name.tar>
tar tvzf <tar_file_name.tar.gz>

## extract all files from tar
tar -xvf <tar_file_name.tar>

## decompress a zip archive file
gzip -d <gunzip compressed file>



#######################################################################################################
-- grep for multiple strings

-- Case 1: OR condition - check for lines where any of the search string is present
grep "str1\|str2" file_to_search
OR
echo "str1" > text_to_search.txt;
echo "str2" > text_to_search.txt;
grep -f text_to_search.txt file_to_search

-- Case 2: AND condition - check for lines where all of the search strings are present in specified order
grep "str1.*str2" file_to_search

#######################################################################################################
misc commands
#######################################################################################################

## prints directory and subdirectory representation (needs UTF-8 e.g. In Putty > Settings > Window > Translation > Received data assumed to be in which characterset)
tree {dir}

## extract text by position and check if non-digits
cut -b10-15 file.txt | grep -v "^[0-9]*$"

## read a file and print each line
while read line; do echo $line; done < file.txt

## copy specified files in a "file" to given directory
while read filepath; do cp $filepath {dest_dir}; done < file_with_filepaths_to_copy.txt


